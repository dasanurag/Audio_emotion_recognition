{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\nimport os\nimport matplotlib.pyplot as plt\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"###### import libraries\nimport librosa\nimport wave\nimport keras\nfrom keras.utils import to_categorical\nfrom keras.models import Sequential\nfrom keras.layers import *\nfrom keras.optimizers import rmsprop","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def extract_mfcc(wav_file_name):\n    '''This function extracts mfcc features and obtain the mean of each dimension\n    Input : path_to_wav_file\n    Output: mfcc_features'''\n    y, sr = librosa.load(wav_file_name)\n#     trimmed_data = np.zeros((160, 20))\n    mfccs = np.mean(librosa.feature.mfcc(y=y, sr=sr, n_mfcc=40).T,axis=0)\n#     data = np.array(librosa.feature.mfcc(y = y, sr = sr, n_mfcc=40).T)\n#     if data.shape[0] <= 160:\n#         trimmed_data[:data.shape[0],0:] = data[:,0:]\n#     else:\n#         trimmed_data[0:,0:] = data[0:160,0:]\n    return mfccs","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"### extract audio data from AV RAVDESS data\nroot_dir = \"../input/ravdess-audiof-files-from-video/ravdess_av/Audio_only/\" \n\naudio_only_data = [] ###stores the mfcc data\naudio_only_labels = [] ###stores the labels\nfor subdirs, dirs, files in os.walk(root_dir):\n    for file in files:\n        y, sr = librosa.load(os.path.join(subdirs,file))\n        mfccs = np.mean(librosa.feature.mfcc(y=y, sr=sr, n_mfcc=40).T,axis=0)\n        audio_only_data.append(mfccs)\n        audio_only_labels.append(int(file[7:8]) - 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#### convert data to array and make labels categorical\naudio_only_data_array = np.array(audio_only_data)\naudio_only_labels_array = np.array(audio_only_labels)\naudio_only_data_array.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"##### load data from savee dataset\n#### although, we load the data here, it is not used in training or validation\nroot_dir = \"../input/savee-emotion-recognition/audiodata/AudioData/\"\n# root_dir = \"../input/audio_speech_actors_01-24/\"\nsavee_data = []\nsavee_labels = []\nfor actor_dir in sorted(os.listdir(root_dir)):\n    if actor_dir[-4:] == \".txt\":\n        continue\n    for file_name in os.listdir(os.path.join(root_dir, actor_dir)):\n        if file_name[0] == \"c\":\n            continue\n        wav_file_name = os.path.join(root_dir, actor_dir, file_name)\n        savee_data.append(extract_mfcc(wav_file_name))\n        if file_name[0] == \"n\":\n            savee_labels.append(0)\n        if file_name[0] == \"a\":\n            savee_labels.append(4)\n        if file_name[0] == \"d\":\n            savee_labels.append(6)\n        if file_name[0] == \"f\":\n            savee_labels.append(5)\n        if file_name[0] == \"h\":\n            savee_labels.append(2)\n        if file_name[:2] == \"sa\":\n            savee_labels.append(3)\n        if file_name[:2] == \"su\":\n            savee_labels.append(7)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#### convert data to array and make labels categorical\nsavee_data_array = np.asarray(savee_data)\nsavee_label_array = np.array(savee_labels)\nto_categorical(savee_label_array)[0].shape\n# savee_data_array.shape","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"##### load radvess speech data #####\nroot_dir = \"../input/ravdess-emotional-speech-audio/audio_speech_actors_01-24/\"\n# root_dir = \"../input/audio_speech_actors_01-24/\"\n# actor_dir = os.listdir(\"../input/audio_speech_actors_01-24/\")\nradvess_speech_labels = []\nravdess_speech_data = []\nfor actor_dir in sorted(os.listdir(root_dir)):\n    actor_name = os.path.join(root_dir, actor_dir)\n    for file in os.listdir(actor_name):\n        radvess_speech_labels.append(int(file[7:8]) - 1)\n        wav_file_name = os.path.join(root_dir, actor_dir, file)\n        ravdess_speech_data.append(extract_mfcc(wav_file_name))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#### convert data to array and make labels categorical\nravdess_speech_data_array = np.asarray(ravdess_speech_data)\nravdess_speech_label_array = np.array(radvess_speech_labels)\nravdess_speech_label_array.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"### load RAVDESS song data\nroot_dir = \"../input/ravdess-song-files/audio_song_actors_01-24/\"\nradvess_song_labels = []\nravdess_song_data = []\nfor actor_dir in sorted(os.listdir(root_dir)):\n    actor_name = os.path.join(root_dir, actor_dir)\n    for file in os.listdir(actor_name):\n        radvess_song_labels.append(int(file[7:8]) - 1)\n        wav_file_name = os.path.join(root_dir, actor_dir, file)\n        ravdess_song_data.append(extract_mfcc(wav_file_name))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#### convert data to array and make labels categorical\nravdess_song_data_array = np.asarray(ravdess_song_data)\nravdess_song_label_array = np.array(radvess_song_labels)\nravdess_song_label_array.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# #### combine data\ndata = np.r_[audio_only_data_array, ravdess_speech_data_array, ravdess_song_data_array]\nlabels = np.r_[audio_only_labels_array, ravdess_speech_label_array, ravdess_song_label_array]\n# data = ravdess_speech_data_array\n# labels = ravdess_speech_label_array\nlabels.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"### plot a histogram to understand the distribution of the data\nimport matplotlib.pyplot as plt\nplt.hist(labels)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"### make categorical labels\nlabels_categorical = to_categorical(labels)\ndata.shape\nlabels_categorical.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_model_LSTM():\n    ### LSTM model, referred to the model A in the report\n    model = Sequential()\n    model.add(LSTM(128, return_sequences=False, input_shape=(40, 1)))\n    model.add(Dense(64))\n    model.add(Dropout(0.4))\n    model.add(Activation('relu'))\n    model.add(Dense(32))\n    model.add(Dropout(0.4))\n    model.add(Activation('relu'))\n    model.add(Dense(8))\n    model.add(Activation('softmax'))\n\n    model.compile(loss='categorical_crossentropy', optimizer='Adam', metrics=['accuracy'])\n    return model\n\ndef create_model_CNN():\n    ### CNN model, referred to the model B in the report\n    model = Sequential()\n    model.add(Conv1D(8, kernel_size = 3, input_shape=(40, 1)))\n    model.add(Activation('relu'))\n    model.add(Conv1D(16,kernel_size = 3))\n    model.add(Activation('relu'))\n    model.add(MaxPooling1D(pool_size=2))\n    model.add(Conv1D(32, kernel_size = 3))\n    model.add(Activation('relu'))\n    model.add(Conv1D(16, kernel_size = 3))\n    model.add(Activation('relu'))\n    model.add(MaxPooling1D(pool_size=2))\n    model.add(Flatten())\n    model.add(Dense(8))\n    model.add(Activation('softmax'))\n    model.compile(loss='categorical_crossentropy', optimizer='Adam', metrics=['accuracy'])\n    return model\n\ndef new_CNN():\n    ### CNN model, referred to the model C in the report\n    model = Sequential()\n    model.add(Conv1D(8, 5,padding='same', input_shape=(40, 1)))\n    model.add(Activation('relu'))\n    model.add(Conv1D(16, 5,padding='same'))\n    model.add(Activation('relu'))\n    model.add(Dropout(0.1))\n    model.add(MaxPooling1D(pool_size=(8)))\n    model.add(Conv1D(32, 5,padding='same',))\n    model.add(Activation('relu'))\n    model.add(Dropout(0.2))\n    model.add(Conv1D(16, 5,padding='same',))\n    model.add(Activation('relu'))\n    model.add(Flatten())\n    model.add(Dense(8))\n    model.add(Activation('softmax'))\n    opt = rmsprop(lr=0.00001, decay=1e-6)\n    model.compile(loss='categorical_crossentropy', optimizer='Adam',metrics=['accuracy'])\n    return model\n\ndef train_CNN():\n    ### CNN model, referred to the model D in the report\n    model = Sequential()\n    model.add(Conv1D(128, 5,padding='same',\n                 input_shape=(40,1)))\n    model.add(Activation('relu'))\n    model.add(Dropout(0.1))\n    model.add(MaxPooling1D(pool_size=(8)))\n    model.add(Conv1D(128, 5,padding='same',))\n    model.add(Activation('relu'))\n    model.add(Dropout(0.1))\n    model.add(Flatten())\n    model.add(Dense(8))\n    model.add(Activation('softmax'))\n    opt = keras.optimizers.rmsprop(lr=0.00005, rho=0.9, epsilon=None, decay=0.0)\n    \n\n    model.compile(loss='categorical_crossentropy',\n              optimizer=opt,\n              metrics=['accuracy'])\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"number_of_samples = data.shape[0]\ntraining_samples = int(number_of_samples * 0.8)\nvalidation_samples = int(number_of_samples * 0.1)\ntest_samples = int(number_of_samples * 0.1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"### train using model A\nmodel_A = create_model_LSTM()\nhistory = model_A.fit(np.expand_dims(data[:training_samples],-1), labels_categorical[:training_samples], validation_data=(np.expand_dims(data[training_samples:training_samples+validation_samples], -1), labels_categorical[training_samples:training_samples+validation_samples]), epochs=100, shuffle=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"### loss plots using model A\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs = range(1, len(loss) + 1)\n\nplt.plot(epochs, loss, 'ro', label='Training loss')\nplt.plot(epochs, val_loss, 'b', label='Validation loss')\nplt.title('Training and validation loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"### accuracy plots using model A\nplt.clf()                                                \n\nacc = history.history['acc']\nval_acc = history.history['val_acc']\n\nplt.plot(epochs, acc, 'ro', label='Training acc')\nplt.plot(epochs, val_acc, 'b', label='Validation acc')\nplt.title('Training and validation accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"### evaluate using model A\nmodel_A.evaluate(np.expand_dims(data[training_samples + validation_samples:], -1), labels_categorical[training_samples + validation_samples:])\n# model.evaluate(predictions, labels_categorical[training_samples + validation_samples:])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"### train using model C\nmodel_C = new_CNN()\nhistory = model_C.fit(np.expand_dims(data[:training_samples],-1), labels_categorical[:training_samples], validation_data=(np.expand_dims(data[training_samples:training_samples+validation_samples], -1), labels_categorical[training_samples:training_samples+validation_samples]), epochs=100, shuffle=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"### loss plots using model C\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs = range(1, len(loss) + 1)\n\nplt.plot(epochs, loss, 'ro', label='Training loss')\nplt.plot(epochs, val_loss, 'b', label='Validation loss')\nplt.title('Training and validation loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"### accuracy plots using model C\nplt.clf()                                                \n\nacc = history.history['acc']\nval_acc = history.history['val_acc']\n\nplt.plot(epochs, acc, 'ro', label='Training acc')\nplt.plot(epochs, val_acc, 'b', label='Validation acc')\nplt.title('Training and validation accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"### evaluate using model C\nmodel_C.evaluate(np.expand_dims(data[training_samples + validation_samples:], -1), labels_categorical[training_samples + validation_samples:])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"### train using model B \nmodel_B = create_model_CNN()\nhistory = model_B.fit(np.expand_dims(data[:training_samples],-1), labels_categorical[:training_samples], validation_data=(np.expand_dims(data[training_samples:training_samples+validation_samples], -1), labels_categorical[training_samples:training_samples+validation_samples]), epochs=100, shuffle=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"### loss plots using model B\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs = range(1, len(loss) + 1)\n\nplt.plot(epochs, loss, 'ro', label='Training loss')\nplt.plot(epochs, val_loss, 'b', label='Validation loss')\nplt.title('Training and validation loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"### accuracy plots using model B\nplt.clf()                                                \n\nacc = history.history['acc']\nval_acc = history.history['val_acc']\n\nplt.plot(epochs, acc, 'ro', label='Training acc')\nplt.plot(epochs, val_acc, 'b', label='Validation acc')\nplt.title('Training and validation accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"###  evaluate using model B\nmodel_B.evaluate(np.expand_dims(data[training_samples + validation_samples:], -1), labels_categorical[training_samples + validation_samples:])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"### train using model D\nmodel_D = train_CNN()\nhistory = model_D.fit(np.expand_dims(data[:training_samples],-1), labels_categorical[:training_samples], validation_data=(np.expand_dims(data[training_samples:training_samples+validation_samples], -1), labels_categorical[training_samples:training_samples+validation_samples]), epochs=100, shuffle=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"### loss plots using model D\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs = range(1, len(loss) + 1)\n\nplt.plot(epochs, loss, 'ro', label='Training loss')\nplt.plot(epochs, val_loss, 'b', label='Validation loss')\nplt.title('Training and validation loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"### accuracy plots using model D\nplt.clf()                                                \n\nacc = history.history['acc']\nval_acc = history.history['val_acc']\n\nplt.plot(epochs, acc, 'ro', label='Training acc')\nplt.plot(epochs, val_acc, 'b', label='Validation acc')\nplt.title('Training and validation accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"### evaluate using model D\nmodel_D.evaluate(np.expand_dims(data[training_samples + validation_samples:], -1), labels_categorical[training_samples + validation_samples:])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_B.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sn\nfrom sklearn.metrics import confusion_matrix\ncm = confusion_matrix(model_D.predict_classes(np.expand_dims(data[training_samples + validation_samples:], -1)), labels[training_samples + validation_samples:])\nsn.set(font_scale=1.4)#for label size\nsn.heatmap(cm, annot=True,annot_kws={\"size\": 16})# font size","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_A.save_weights(\"Model_A.h5\")\nmodel_B.save_weights(\"Model_B.h5\")\nmodel_C.save_weights(\"Model_C.h5\")\nmodel_D.save_weights(\"Model_D.h5\")","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}